# ComfyUI Model Resolver v2.0 - 任务分解文档

## 架构设计

基于 **FastAPI + Gradio** 架构，实现前后端分离，便于后续功能迭代。

```
┌─────────────────┐     HTTP/WebSocket    ┌─────────────────┐
│  Gradio Client  │ ◄──────────────────► │  FastAPI Server │
│   (Frontend)    │                       │   (Backend API)  │
└─────────────────┘                       └─────────────────┘
                                                    │
                                          ┌─────────┴─────────┐
                                          │   Core Modules    │
                                          │  (已完成的脚本)   │
                                          └───────────────────┘
```

## Phase 1: API 层设计与实现（3天）

### Task 1.1: FastAPI 项目结构搭建（0.5天）

**目标**：创建标准的 FastAPI 项目结构

```
project/
├── api/
│   ├── __init__.py
│   ├── main.py              # FastAPI 主应用
│   ├── routers/             # API 路由
│   │   ├── workflow.py      # 工作流相关API
│   │   ├── search.py        # 搜索相关API
│   │   ├── download.py      # 下载相关API
│   │   └── config.py        # 配置相关API
│   ├── models/              # Pydantic 数据模型
│   │   ├── workflow.py
│   │   ├── search.py
│   │   └── download.py
│   ├── services/            # 业务逻辑层
│   │   ├── workflow_service.py
│   │   ├── search_service.py
│   │   └── download_service.py
│   └── utils/               # 工具函数
├── core/                    # 现有核心模块（复用）
│   ├── workflow_analyzer_v3.py
│   ├── multi_platform_searcher.py
│   └── optimized_search.py
├── frontend/                # Gradio 前端
│   └── app.py
└── data/                    # 数据存储
    └── resolver_data.json
```

### Task 1.2: API 数据模型定义（0.5天）

**目标**：使用 Pydantic 定义所有 API 数据模型

```python
# api/models/workflow.py
from pydantic import BaseModel
from typing import List, Optional, Dict
from datetime import datetime

class WorkflowModel(BaseModel):
    """工作流模型"""
    path: str
    name: str
    status: str  # "ready", "partial", "missing", "unanalyzed"
    total_models: int
    missing_count: int
    last_analyzed: Optional[datetime]

class ModelInfo(BaseModel):
    """模型信息"""
    filename: str
    model_type: str
    exists_locally: bool
    size: Optional[int]
    local_path: Optional[str]
    selected: bool = False  # 是否选中

class AnalyzeRequest(BaseModel):
    """分析请求"""
    workflow_paths: List[str]

class AnalyzeResponse(BaseModel):
    """分析响应"""
    workflows: List[WorkflowModel]
    models: List[ModelInfo]

class SearchRequest(BaseModel):
    """搜索请求"""
    models: List[str]
    platforms: List[str] = ["huggingface", "civitai"]

class SearchResult(BaseModel):
    """搜索结果"""
    filename: str
    sources: List[Dict]  # 包含 url, platform, rating, name
    selected_source: Optional[str]
    custom_url: Optional[str]
```

### Task 1.3: 工作流 API 实现（1天）

**目标**：实现工作流相关的所有 API 端点

```python
# api/routers/workflow.py
from fastapi import APIRouter, HTTPException, Query
from typing import List, Optional
import os

router = APIRouter(prefix="/api/workflow", tags=["workflow"])

@router.get("/list")
async def list_workflows(directory: str = Query(..., description="工作流目录路径")):
    """
    列出目录下的所有工作流
    返回格式：
    [
        {
            "path": "/path/to/workflow.json",
            "name": "workflow.json",
            "status": "partial",
            "total_models": 8,
            "missing_count": 2,
            "last_analyzed": "2024-01-14T10:30:00"
        }
    ]
    """
    # 调用 service 层
    
@router.post("/analyze")
async def analyze_workflows(request: AnalyzeRequest):
    """
    分析工作流，返回模型列表
    """
    # 调用 workflow_analyzer_v3.py
    
@router.get("/status/{workflow_id}")
async def get_workflow_status(workflow_id: str):
    """
    获取单个工作流的详细状态
    """
    # 从 JSON 存储读取

@router.post("/export-script")
async def export_download_script(workflow_paths: List[str]):
    """
    导出下载脚本
    """
    # 生成 bash 脚本
```

### Task 1.4: 搜索 API 实现（1天）

**目标**：实现模型搜索相关的 API

```python
# api/routers/search.py
from fastapi import APIRouter, BackgroundTasks

router = APIRouter(prefix="/api/search", tags=["search"])

@router.post("/models")
async def search_models(request: SearchRequest):
    """
    搜索模型，返回每个模型的多个下载源
    """
    # 调用 multi_platform_searcher.py
    
@router.post("/validate-url")
async def validate_custom_url(url: str):
    """
    验证自定义URL的有效性
    返回：{valid: bool, size: int, filename: str}
    """
    # 发送 HEAD 请求验证

@router.get("/cached-results/{model_hash}")
async def get_cached_results(model_hash: str):
    """
    获取缓存的搜索结果
    """
```

## Phase 2: 业务逻辑层封装（2天）

### Task 2.1: 工作流服务层（0.5天）

**目标**：封装工作流分析的业务逻辑

```python
# api/services/workflow_service.py
from core.workflow_analyzer_v3 import WorkflowAnalyzerV3
from typing import List, Dict
import json
import os

class WorkflowService:
    def __init__(self):
        self.analyzer = WorkflowAnalyzerV3()
        self.data_file = "data/resolver_data.json"
        self._init_data_file()
    
    def scan_directory(self, directory: str) -> List[Dict]:
        """扫描目录获取工作流列表"""
        workflows = []
        for file in os.listdir(directory):
            if file.endswith('.json'):
                filepath = os.path.join(directory, file)
                status = self._get_workflow_status(filepath)
                workflows.append({
                    "path": filepath,
                    "name": file,
                    "status": status['status'],
                    "total_models": status['total_models'],
                    "missing_count": status['missing_count'],
                    "last_analyzed": status.get('last_analyzed')
                })
        return workflows
    
    def analyze_workflow(self, workflow_path: str) -> Dict:
        """分析单个工作流"""
        # 调用现有的 analyzer
        result = self.analyzer.analyze(workflow_path)
        
        # 检查本地文件
        models_with_status = self._check_local_models(result['models'])
        
        # 保存结果
        self._save_analysis_result(workflow_path, models_with_status)
        
        return {
            "workflow": workflow_path,
            "models": models_with_status
        }
    
    def _check_local_models(self, models: List[Dict]) -> List[Dict]:
        """检查模型的本地存在状态"""
        # 复用 check_local_models 函数
        pass
```

### Task 2.2: 搜索服务层（0.5天）

**目标**：封装模型搜索逻辑

```python
# api/services/search_service.py
from core.multi_platform_searcher import MultiPlatformSearcher
from core.optimized_search import OptimizedModelSearcher
import os
import asyncio

class SearchService:
    def __init__(self):
        self.searcher = MultiPlatformSearcher(
            civitai_token=os.getenv('CIVITAI_API_KEY')
        )
        self.optimizer = OptimizedModelSearcher()
    
    async def search_models(self, models: List[Dict]) -> Dict:
        """批量搜索模型"""
        results = {}
        
        # 并发搜索
        tasks = []
        for model in models:
            task = self._search_single_model(model)
            tasks.append(task)
        
        search_results = await asyncio.gather(*tasks)
        
        # 组织结果
        for model, result in zip(models, search_results):
            results[model['filename']] = {
                'sources': result['sources'],
                'recommended': result['sources'][0] if result['sources'] else None
            }
        
        return results
    
    async def _search_single_model(self, model: Dict) -> Dict:
        """搜索单个模型"""
        # 调用现有搜索逻辑
        results = await self.searcher.search(
            model['filename'],
            model_type=model.get('model_type')
        )
        
        # 添加评分
        for source in results:
            source['rating'] = self._calculate_rating(source)
        
        # 排序
        results.sort(key=lambda x: x['rating'], reverse=True)
        
        return {'sources': results}
```

### Task 2.3: 下载服务层（1天）

**目标**：实现下载队列管理

```python
# api/services/download_service.py
import asyncio
from typing import Dict, List, Optional
import aiohttp
import aiofiles
import os
from datetime import datetime

class DownloadService:
    def __init__(self):
        self.download_queue = asyncio.Queue()
        self.active_downloads = {}
        self.completed_downloads = []
        self.is_running = False
        
    async def start_worker(self):
        """启动下载工作线程"""
        self.is_running = True
        while self.is_running:
            try:
                task = await asyncio.wait_for(
                    self.download_queue.get(), 
                    timeout=1.0
                )
                await self._process_download(task)
            except asyncio.TimeoutError:
                continue
    
    async def add_to_queue(self, download_task: Dict):
        """添加到下载队列"""
        task_id = f"{download_task['filename']}_{datetime.now().timestamp()}"
        download_task['id'] = task_id
        download_task['status'] = 'queued'
        
        await self.download_queue.put(download_task)
        return task_id
    
    async def get_status(self) -> Dict:
        """获取下载状态"""
        return {
            "queue_size": self.download_queue.qsize(),
            "active": list(self.active_downloads.values()),
            "completed": self.completed_downloads[-10:]  # 最近10个
        }
    
    async def _process_download(self, task: Dict):
        """处理单个下载任务"""
        task_id = task['id']
        self.active_downloads[task_id] = {
            'filename': task['filename'],
            'progress': 0,
            'speed': 0,
            'status': 'downloading'
        }
        
        try:
            await self._download_file(
                task['url'],
                task['target_path'],
                task_id
            )
            
            self.completed_downloads.append({
                'filename': task['filename'],
                'status': 'success',
                'completed_at': datetime.now().isoformat()
            })
        except Exception as e:
            self.completed_downloads.append({
                'filename': task['filename'],
                'status': 'failed',
                'error': str(e),
                'completed_at': datetime.now().isoformat()
            })
        finally:
            del self.active_downloads[task_id]
```

## Phase 3: Gradio 前端开发（3天）

### Task 3.1: API 客户端封装（0.5天）

**目标**：创建与后端 API 通信的客户端

```python
# frontend/api_client.py
import httpx
from typing import List, Dict, Optional
import asyncio

class APIClient:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=30.0)
    
    async def list_workflows(self, directory: str) -> List[Dict]:
        """获取工作流列表"""
        response = await self.client.get(
            f"{self.base_url}/api/workflow/list",
            params={"directory": directory}
        )
        response.raise_for_status()
        return response.json()
    
    async def analyze_workflows(self, paths: List[str]) -> Dict:
        """分析工作流"""
        response = await self.client.post(
            f"{self.base_url}/api/workflow/analyze",
            json={"workflow_paths": paths}
        )
        response.raise_for_status()
        return response.json()
    
    async def search_models(self, models: List[str]) -> Dict:
        """搜索模型"""
        response = await self.client.post(
            f"{self.base_url}/api/search/models",
            json={"models": models}
        )
        response.raise_for_status()
        return response.json()
    
    async def add_download(self, download_info: Dict) -> str:
        """添加下载任务"""
        response = await self.client.post(
            f"{self.base_url}/api/download/add",
            json=download_info
        )
        response.raise_for_status()
        return response.json()['task_id']
```

### Task 3.2: Gradio 界面组件（1天）

**目标**：实现三个主要标签页

```python
# frontend/components.py
import gradio as gr
from typing import List, Dict, Callable
import asyncio

class WorkflowAnalyzerUI:
    def __init__(self, api_client):
        self.api_client = api_client
        self.current_directory = "/workspace/ComfyUI/workflows"
        self.workflow_data = {}
        self.model_data = {}
        
    def create_workflow_tab(self):
        """创建工作流分析标签页"""
        with gr.Tab("工作流分析"):
            # 目录选择
            with gr.Row():
                directory_input = gr.Textbox(
                    value=self.current_directory,
                    label="工作流目录",
                    scale=4
                )
                refresh_btn = gr.Button("🔄刷新", scale=1)
            
            # 工作流列表
            workflow_checklist = gr.CheckboxGroup(
                label="选择工作流",
                choices=[],
                value=[]
            )
            
            # 批量操作
            with gr.Row():
                select_all_btn = gr.Button("全选", size="sm")
                select_none_btn = gr.Button("全不选", size="sm")
                analyze_btn = gr.Button("分析选中的工作流", variant="primary")
                export_script_btn = gr.Button("导出批量下载脚本")
            
            # 分隔线
            gr.Markdown("---")
            
            # 当前工作流详情
            workflow_info = gr.Markdown("请选择工作流查看详情")
            
            # 模型列表
            model_checklist = gr.CheckboxGroup(
                label="模型列表",
                choices=[],
                value=[]
            )
            
            # 模型操作
            with gr.Row():
                select_missing_btn = gr.Button("仅选缺失", size="sm")
                search_btn = gr.Button("搜索选中的模型", variant="primary")
                export_model_script_btn = gr.Button("导出下载脚本")
            
            # 日志
            log_output = gr.Textbox(
                label="操作日志",
                lines=5,
                max_lines=10,
                autoscroll=True
            )
            
            # 事件绑定
            refresh_btn.click(
                fn=self.refresh_workflows,
                inputs=[directory_input],
                outputs=[workflow_checklist, log_output]
            )
            
            analyze_btn.click(
                fn=self.analyze_selected_workflows,
                inputs=[workflow_checklist],
                outputs=[model_checklist, workflow_info, log_output]
            )
            
            return {
                'directory_input': directory_input,
                'workflow_checklist': workflow_checklist,
                'model_checklist': model_checklist,
                'log_output': log_output
            }
```

### Task 3.3: 前端主应用（1天）

**目标**：整合所有组件，创建完整应用

```python
# frontend/app.py
import gradio as gr
import asyncio
from api_client import APIClient
from components import WorkflowAnalyzerUI, SearchResultUI, DownloadManagerUI

class ModelResolverApp:
    def __init__(self):
        self.api_client = APIClient()
        self.workflow_ui = WorkflowAnalyzerUI(self.api_client)
        self.search_ui = SearchResultUI(self.api_client)
        self.download_ui = DownloadManagerUI(self.api_client)
        
    def create_interface(self):
        """创建完整的 Gradio 界面"""
        with gr.Blocks(
            title="ComfyUI Model Resolver v2.0",
            theme=gr.themes.Soft()
        ) as app:
            # 标题
            gr.Markdown("# ComfyUI Model Resolver v2.0")
            
            # 顶部工具栏
            with gr.Row():
                with gr.Column(scale=4):
                    gr.Markdown("智能分析和下载 ComfyUI 工作流所需的模型")
                with gr.Column(scale=1):
                    settings_btn = gr.Button("设置", size="sm")
                    help_btn = gr.Button("帮助", size="sm")
            
            # 主标签页
            with gr.Tabs() as main_tabs:
                # 工作流分析标签
                workflow_components = self.workflow_ui.create_workflow_tab()
                
                # 搜索结果标签
                search_components = self.search_ui.create_search_tab()
                
                # 下载管理标签
                download_components = self.download_ui.create_download_tab()
            
            # 设置弹窗
            with gr.Group(visible=False) as settings_modal:
                self.create_settings_modal()
            
            # 事件处理
            self.setup_event_handlers(
                workflow_components,
                search_components,
                download_components,
                settings_btn,
                settings_modal
            )
        
        return app
    
    def setup_event_handlers(self, workflow, search, download, settings_btn, settings_modal):
        """设置所有事件处理器"""
        # 标签页切换数据传递
        workflow['search_btn'].click(
            fn=lambda x: gr.Tabs.update(selected=1),
            outputs=[main_tabs]
        )
        
        # 设置弹窗
        settings_btn.click(
            fn=lambda: gr.Group.update(visible=True),
            outputs=[settings_modal]
        )

if __name__ == "__main__":
    app = ModelResolverApp()
    interface = app.create_interface()
    
    # 启动应用
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )
```

### Task 3.4: WebSocket 实时更新（0.5天）

**目标**：实现下载进度的实时更新

```python
# frontend/websocket_handler.py
import asyncio
import json
from typing import Callable
import websockets

class WebSocketHandler:
    def __init__(self, ws_url="ws://localhost:8000/ws"):
        self.ws_url = ws_url
        self.callbacks = {}
        
    async def connect_progress_updates(self, callback: Callable):
        """连接 WebSocket 获取进度更新"""
        async with websockets.connect(f"{self.ws_url}/download-progress") as websocket:
            while True:
                try:
                    message = await websocket.recv()
                    data = json.loads(message)
                    
                    if data['type'] == 'progress':
                        await callback(data['data'])
                    elif data['type'] == 'completed':
                        await callback(data['data'])
                        
                except websockets.exceptions.ConnectionClosed:
                    break
                except Exception as e:
                    print(f"WebSocket error: {e}")
                    await asyncio.sleep(1)
```

## Phase 4: 集成与优化（2天）

### Task 4.1: Docker 配置（0.5天）

**目标**：创建容器化部署方案

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY api/ ./api/
COPY core/ ./core/
COPY frontend/ ./frontend/
COPY data/ ./data/

# 复制启动脚本
COPY start.sh .
RUN chmod +x start.sh

# 暴露端口
EXPOSE 8000 7860

# 启动命令
CMD ["./start.sh"]
```

```bash
# start.sh
#!/bin/bash

# 启动 FastAPI 后端
echo "Starting FastAPI backend..."
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload &

# 等待后端启动
echo "Waiting for backend to start..."
sleep 5

# 检查后端是否启动成功
curl -f http://localhost:8000/health || exit 1

# 启动 Gradio 前端
echo "Starting Gradio frontend..."
python frontend/app.py
```

### Task 4.2: 单元测试（0.5天）

**目标**：编写关键功能的单元测试

```python
# tests/test_workflow_api.py
import pytest
from httpx import AsyncClient
from api.main import app

@pytest.mark.asyncio
async def test_list_workflows():
    """测试工作流列表 API"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get(
            "/api/workflow/list",
            params={"directory": "/test/workflows"}
        )
        assert response.status_code == 200
        assert isinstance(response.json(), list)

@pytest.mark.asyncio
async def test_analyze_workflow():
    """测试工作流分析 API"""
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.post(
            "/api/workflow/analyze",
            json={"workflow_paths": ["/test/workflow.json"]}
        )
        assert response.status_code == 200
        data = response.json()
        assert "models" in data
```

### Task 4.3: 性能优化（0.5天）

**目标**：优化关键路径性能

1. **API 响应缓存**
```python
from fastapi_cache import FastAPICache
from fastapi_cache.decorator import cache

@router.get("/workflow/list")
@cache(expire=60)  # 缓存60秒
async def list_workflows(directory: str):
    # ...
```

2. **批量操作优化**
```python
# 使用 asyncio.gather 并发处理
async def batch_analyze(workflows: List[str]):
    tasks = [analyze_single(w) for w in workflows]
    results = await asyncio.gather(*tasks)
    return results
```

3. **数据库连接池**（如果后续使用数据库）

### Task 4.4: 部署文档（0.5天）

**目标**：编写完整的部署和使用文档

```markdown
# 部署指南

## 快速开始

### Docker 部署（推荐）
```bash
docker build -t comfyui-resolver:v2.0 .
docker run -p 7860:7860 -p 8000:8000 \
  -v /workspace:/workspace \
  comfyui-resolver:v2.0
```

### 手动部署
```bash
# 1. 安装依赖
pip install -r requirements.txt

# 2. 设置环境变量
export CIVITAI_API_KEY=your_key
export HF_TOKEN=your_token

# 3. 启动服务
./start.sh
```

## API 文档
访问 http://localhost:8000/docs 查看自动生成的 API 文档

## 配置说明
...
```

## 时间线汇总

| 阶段 | 任务 | 预计时间 | 关键交付物 |
|------|------|----------|-----------|
| Phase 1 | API层设计与实现 | 3天 | RESTful API, WebSocket |
| Phase 2 | 业务逻辑层封装 | 2天 | Service层, 复用现有代码 |
| Phase 3 | Gradio前端开发 | 3天 | 完整UI, 实时更新 |
| Phase 4 | 集成与优化 | 2天 | Docker镜像, 文档 |
| **总计** | | **10天** | |

## 关键技术决策

### 为什么选择 FastAPI + Gradio？

1. **FastAPI 优势**：
   - 自动生成 API 文档
   - 原生异步支持
   - WebSocket 支持
   - 类型安全

2. **前后端分离优势**：
   - 便于后续替换前端（如改为 Vue/React）
   - 支持多客户端（CLI、Web、插件）
   - API 可独立测试和部署
   - 更好的扩展性

3. **复用现有代码**：
   - 核心逻辑不需要重写
   - 只需要封装为 Service 层
   - 降低开发风险

## 风险控制

1. **Gradio 限制**：
   - 某些复杂交互可能需要妥协
   - 解决方案：使用 gr.HTML 自定义组件

2. **性能问题**：
   - 大量模型搜索可能较慢
   - 解决方案：异步处理 + 进度反馈

3. **网络问题**：
   - 下载可能中断
   - 解决方案：断点续传 + 重试机制